{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Env Setup"
      ],
      "metadata": {
        "id": "Rv_vwDO8x0AK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain-openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8z2sdcevtmdB",
        "outputId": "0aa9e007-f7f7-413a-814f-0bee834fb321"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.1.7-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.6 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.2.7)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (2.15.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.6.4)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (2.12.3)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.13.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.32.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain-openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.6->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.6->langchain-openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.5.0)\n",
            "Downloading langchain_openai-1.1.7-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.8/84.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-openai\n",
            "Successfully installed langchain-openai-1.1.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"LANGSMITH_TRACING\"]=\"true\"\n",
        "os.environ[\"LANGSMITH_API_KEY\"] =\"\""
      ],
      "metadata": {
        "id": "ZEWDP1WMuZmm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.chat_models import init_chat_model\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "model = init_chat_model(\"gpt-4.1\")\n"
      ],
      "metadata": {
        "id": "wtkKuBt2uEcj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Langchain Docs\n",
        "\n"
      ],
      "metadata": {
        "id": "6FPH-DZZP87e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Skills"
      ],
      "metadata": {
        "id": "IgsIy_EUxWFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict\n",
        "\n",
        "class Skill(TypedDict):\n",
        "    name: str\n",
        "    description: str\n",
        "    content: str\n",
        "\n",
        "SKILLS: list[Skill] = [\n",
        "    {\n",
        "    \"name\": \"fairouz\",\n",
        "    \"description\":\n",
        "        \"Use this skill whenever the user asks about Fairouz or her songs. \"\n",
        "        \"It provides structured cultural and musical explanations.\"\n",
        "    ,\n",
        "    \"content\": \"\"\"\n",
        "          You are a cultural music expert specializing in Fairouz and her work.\n",
        "\n",
        "          For every question about a Fairouz song, respond in the following structured format:\n",
        "\n",
        "          Lyrics Overview:\n",
        "          - Briefly describe the theme, emotions, and key imagery of the songâ€™s lyrics.\n",
        "          - Do not quote full lyrics; summarize and interpret instead.\n",
        "\n",
        "          Author & Composer:\n",
        "          - Identify the lyricist and composer (e.g., the Rahbani Brothers, Ziad Rahbani).\n",
        "          - If the authorship is uncertain or disputed, clearly state that.\n",
        "\n",
        "          Origin & Inspiration:\n",
        "          - Explain the cultural, historical, or personal inspiration behind the song.\n",
        "          - Mention whether it reflects Lebanese folklore, political context, nostalgia, love, exile, nature, or national identity.\n",
        "\n",
        "          Cultural Significance (optional but encouraged):\n",
        "          - Describe why the song is important or beloved in Lebanese or Arab culture.\n",
        "\n",
        "          OUTPUT FORMAT (use exactly):\n",
        "          Lyrics Overview:\n",
        "          ...\n",
        "\n",
        "          Author & Composer:\n",
        "          ...\n",
        "\n",
        "          Origin & Inspiration:\n",
        "          ...\n",
        "\n",
        "          Cultural Significance:\n",
        "          ...\n",
        "          \"\"\",\n",
        "},\n",
        "]\n"
      ],
      "metadata": {
        "id": "i4rc8RTnvgGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Skill Loading Tool"
      ],
      "metadata": {
        "id": "NBXMo-QjxbZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import tool\n",
        "\n",
        "@tool\n",
        "def load_skill(skill_name: str) -> str:\n",
        "    \"\"\"Load the full content of a skill into the agent's context.\n",
        "\n",
        "    Use this when you need detailed information about how to handle a specific\n",
        "    type of request. This will provide you with comprehensive instructions,\n",
        "    policies, and guidelines for the skill area.\n",
        "\n",
        "    Args:\n",
        "        skill_name: The name of the skill to load (e.g., \"expense_reporting\", \"travel_booking\")\n",
        "    \"\"\"\n",
        "    # Find and return the requested skill\n",
        "    for skill in SKILLS:\n",
        "        if skill[\"name\"] == skill_name:\n",
        "            return f\"Loaded skill: {skill_name}\\n\\n{skill['content']}\"\n",
        "\n",
        "    # Skill not found\n",
        "    available = \", \".join(s[\"name\"] for s in SKILLS)\n",
        "    return f\"Skill '{skill_name}' not found. Available skills: {available}\""
      ],
      "metadata": {
        "id": "gsf-81B_vgI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Skill Middleware"
      ],
      "metadata": {
        "id": "RlbmI8tbxfaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents.middleware import ModelRequest, ModelResponse, AgentMiddleware\n",
        "from langchain.messages import SystemMessage\n",
        "from typing import Callable\n",
        "\n",
        "class SkillMiddleware(AgentMiddleware):\n",
        "    \"\"\"Middleware that injects skill descriptions into the system prompt.\"\"\"\n",
        "\n",
        "    # Register the load_skill tool as a class variable\n",
        "    tools = [load_skill]\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize and generate the skills prompt from SKILLS.\"\"\"\n",
        "        # Build skills prompt from the SKILLS list\n",
        "        skills_list = []\n",
        "        for skill in SKILLS:\n",
        "            skills_list.append(\n",
        "                f\"- **{skill['name']}**: {skill['description']}\"\n",
        "            )\n",
        "        self.skills_prompt = \"\\n\".join(skills_list)\n",
        "\n",
        "    def wrap_model_call(\n",
        "        self,\n",
        "        request: ModelRequest,\n",
        "        handler: Callable[[ModelRequest], ModelResponse],\n",
        "    ) -> ModelResponse:\n",
        "        \"\"\"Sync: Inject skill descriptions into system prompt.\"\"\"\n",
        "        # Build the skills addendum\n",
        "        skills_addendum = (\n",
        "            f\"\\n\\n## Available Skills\\n\\n{self.skills_prompt}\\n\\n\"\n",
        "            \"Use the load_skill tool when you need detailed information \"\n",
        "            \"about handling a specific type of request.\"\n",
        "        )\n",
        "\n",
        "        # Append to system message content blocks\n",
        "        new_content = list(request.system_message.content_blocks) + [\n",
        "            {\"type\": \"text\", \"text\": skills_addendum}\n",
        "        ]\n",
        "        print(self.skills_prompt)\n",
        "        new_system_message = SystemMessage(content=new_content)\n",
        "        modified_request = request.override(system_message=new_system_message)\n",
        "        return handler(modified_request)"
      ],
      "metadata": {
        "id": "w1Ql0DaTvgLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agent with Skill Support"
      ],
      "metadata": {
        "id": "ZhgRsGAZxlHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import create_agent\n",
        "from langgraph.checkpoint.memory import InMemorySaver\n",
        "\n",
        "# Create the agent with skill support\n",
        "agent = create_agent(\n",
        "    model,\n",
        "    system_prompt=(\n",
        "        \"You are a helpful assistant. \"\n",
        "        \"Your user might ask you questions about Fairouz. \"\n",
        "        \"When they do, you MUST use the load_skill tool to load the 'fairouz' skill first, \"\n",
        "        \"then follow its instructions to answer the question.\"\n",
        "    ),\n",
        "    middleware=[SkillMiddleware()],\n",
        "    checkpointer=InMemorySaver(),\n",
        ")"
      ],
      "metadata": {
        "id": "ZFCrYpm9vgOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Agent"
      ],
      "metadata": {
        "id": "33uq61XOxtzG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "\n",
        "# Configuration for this conversation thread\n",
        "thread_id = str(uuid.uuid4())\n",
        "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
        "\n",
        "# Ask for a SQL query\n",
        "result = agent.invoke(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": (\n",
        "                    \"badaak ala bali\"\n",
        "                ),\n",
        "            }\n",
        "        ]\n",
        "    },\n",
        "    config\n",
        ")\n",
        "\n",
        "# Print the conversation\n",
        "for message in result[\"messages\"]:\n",
        "    if hasattr(message, 'pretty_print'):\n",
        "        message.pretty_print()\n",
        "    else:\n",
        "        print(f\"{message.type}: {message.content}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "navbT-B7vgR8",
        "outputId": "c4111648-207a-4c63-b040-7fc0f7d92250"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- **fairouz**: Use this skill whenever the user asks about Fairouz or her songs. It provides structured cultural and musical explanations.\n",
            "- **fairouz**: Use this skill whenever the user asks about Fairouz or her songs. It provides structured cultural and musical explanations.\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "badaak ala bali\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  load_skill (call_mFjlvA4uArcPeitJTeTvPHND)\n",
            " Call ID: call_mFjlvA4uArcPeitJTeTvPHND\n",
            "  Args:\n",
            "    skill_name: fairouz\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: load_skill\n",
            "\n",
            "Loaded skill: fairouz\n",
            "\n",
            "\n",
            "          You are a cultural music expert specializing in Fairouz and her work.\n",
            "\n",
            "          For every question about a Fairouz song, respond in the following structured format:\n",
            "\n",
            "          Lyrics Overview:\n",
            "          - Briefly describe the theme, emotions, and key imagery of the songâ€™s lyrics.\n",
            "          - Do not quote full lyrics; summarize and interpret instead.\n",
            "\n",
            "          Author & Composer:\n",
            "          - Identify the lyricist and composer (e.g., the Rahbani Brothers, Ziad Rahbani).\n",
            "          - If the authorship is uncertain or disputed, clearly state that.\n",
            "\n",
            "          Origin & Inspiration:\n",
            "          - Explain the cultural, historical, or personal inspiration behind the song.\n",
            "          - Mention whether it reflects Lebanese folklore, political context, nostalgia, love, exile, nature, or national identity.\n",
            "\n",
            "          Cultural Significance (optional but encouraged):\n",
            "          - Describe why the song is important or beloved in Lebanese or Arab culture.\n",
            "\n",
            "          OUTPUT FORMAT (use exactly):\n",
            "          Lyrics Overview:\n",
            "          ...\n",
            "\n",
            "          Author & Composer:\n",
            "          ...\n",
            "\n",
            "          Origin & Inspiration:\n",
            "          ...\n",
            "\n",
            "          Cultural Significance:\n",
            "          ...\n",
            "          \n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Lyrics Overview:\n",
            "\"Badaak ala bali\" is a moving Fairouz song that reflects feelings of yearning and longing for someone. The theme, strongly tinted with nostalgia and deep affection, follows the protagonist's thoughts as they return to a cherished individual who remains on their mind.\n",
            "\n",
            "Author & Composer:\n",
            "\"Badaak ala bali\" is composed by the phenomenal Rahbani Brothers, who often partnered with Fairouz to create some of her most memorable pieces.\n",
            "\n",
            "Origin & Inspiration:\n",
            "\"Badaak ala bali\", like many of Fairouz and the Rahbani Brothers' songs, lays its roots in the Lebanese culture, telling stories of love, longing, and nostalgia, which are recurring themes in this culture's folklore. \n",
            "\n",
            "Cultural Significance:\n",
            "The song is celebrated in Lebanese and Arab culture for its heartfelt lyrics and melody that resonate with the common feelings of longing and love. It's particularly cherished because of the way it gives voice to emotion and thought, especially the sentiment of having someone constantly in your mind.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent = create_agent(\n",
        "    model,\n",
        "    tools=[load_skill],  # Tool is available\n",
        "    system_prompt=(\n",
        "        \"You are a helpful assistant. \"\n",
        "        \"When you need detailed instructions for handling specific topics, \"\n",
        "        \"use the available tools to load the relevant skill content.\"\n",
        "    ),\n",
        "    middleware=[SkillMiddleware()],\n",
        "    checkpointer=InMemorySaver(),\n",
        ")"
      ],
      "metadata": {
        "id": "gnrlJVSsy0Hx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Langchain Example"
      ],
      "metadata": {
        "id": "QLm8eTbpQnHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "from typing import TypedDict, NotRequired\n",
        "from langchain.tools import tool\n",
        "from langchain.agents import create_agent\n",
        "from langchain.agents.middleware import ModelRequest, ModelResponse, AgentMiddleware\n",
        "from langchain.messages import SystemMessage\n",
        "from langgraph.checkpoint.memory import InMemorySaver\n",
        "from typing import Callable\n",
        "\n",
        "# Define skill structure\n",
        "class Skill(TypedDict):\n",
        "    \"\"\"A skill that can be progressively disclosed to the agent.\"\"\"\n",
        "    name: str\n",
        "    description: str\n",
        "    content: str\n",
        "\n",
        "# Define skills with schemas and business logic\n",
        "SKILLS: list[Skill] = [\n",
        "    {\n",
        "        \"name\": \"sales_analytics\",\n",
        "        \"description\": \"Database schema and business logic for sales data analysis including customers, orders, and revenue.\",\n",
        "        \"content\": \"\"\"# Sales Analytics Schema\n",
        "\n",
        "## Tables\n",
        "\n",
        "### customers\n",
        "- customer_id (PRIMARY KEY)\n",
        "- name\n",
        "- email\n",
        "- signup_date\n",
        "- status (active/inactive)\n",
        "- customer_tier (bronze/silver/gold/platinum)\n",
        "\n",
        "### orders\n",
        "- order_id (PRIMARY KEY)\n",
        "- customer_id (FOREIGN KEY -> customers)\n",
        "- order_date\n",
        "- status (pending/completed/cancelled/refunded)\n",
        "- total_amount\n",
        "- sales_region (north/south/east/west)\n",
        "\n",
        "### order_items\n",
        "- item_id (PRIMARY KEY)\n",
        "- order_id (FOREIGN KEY -> orders)\n",
        "- product_id\n",
        "- quantity\n",
        "- unit_price\n",
        "- discount_percent\n",
        "\n",
        "## Business Logic\n",
        "\n",
        "**Active customers**: status = 'active' AND signup_date <= CURRENT_DATE - INTERVAL '90 days'\n",
        "\n",
        "**Revenue calculation**: Only count orders with status = 'completed'. Use total_amount from orders table, which already accounts for discounts.\n",
        "\n",
        "**Customer lifetime value (CLV)**: Sum of all completed order amounts for a customer.\n",
        "\n",
        "**High-value orders**: Orders with total_amount > 1000\n",
        "\n",
        "## Example Query\n",
        "\n",
        "-- Get top 10 customers by revenue in the last quarter\n",
        "SELECT\n",
        "    c.customer_id,\n",
        "    c.name,\n",
        "    c.customer_tier,\n",
        "    SUM(o.total_amount) as total_revenue\n",
        "FROM customers c\n",
        "JOIN orders o ON c.customer_id = o.customer_id\n",
        "WHERE o.status = 'completed'\n",
        "  AND o.order_date >= CURRENT_DATE - INTERVAL '3 months'\n",
        "GROUP BY c.customer_id, c.name, c.customer_tier\n",
        "ORDER BY total_revenue DESC\n",
        "LIMIT 10;\n",
        "\"\"\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"inventory_management\",\n",
        "        \"description\": \"Database schema and business logic for inventory tracking including products, warehouses, and stock levels.\",\n",
        "        \"content\": \"\"\"# Inventory Management Schema\n",
        "\n",
        "## Tables\n",
        "\n",
        "### products\n",
        "- product_id (PRIMARY KEY)\n",
        "- product_name\n",
        "- sku\n",
        "- category\n",
        "- unit_cost\n",
        "- reorder_point (minimum stock level before reordering)\n",
        "- discontinued (boolean)\n",
        "\n",
        "### warehouses\n",
        "- warehouse_id (PRIMARY KEY)\n",
        "- warehouse_name\n",
        "- location\n",
        "- capacity\n",
        "\n",
        "### inventory\n",
        "- inventory_id (PRIMARY KEY)\n",
        "- product_id (FOREIGN KEY -> products)\n",
        "- warehouse_id (FOREIGN KEY -> warehouses)\n",
        "- quantity_on_hand\n",
        "- last_updated\n",
        "\n",
        "### stock_movements\n",
        "- movement_id (PRIMARY KEY)\n",
        "- product_id (FOREIGN KEY -> products)\n",
        "- warehouse_id (FOREIGN KEY -> warehouses)\n",
        "- movement_type (inbound/outbound/transfer/adjustment)\n",
        "- quantity (positive for inbound, negative for outbound)\n",
        "- movement_date\n",
        "- reference_number\n",
        "\n",
        "## Business Logic\n",
        "\n",
        "**Available stock**: quantity_on_hand from inventory table where quantity_on_hand > 0\n",
        "\n",
        "**Products needing reorder**: Products where total quantity_on_hand across all warehouses is less than or equal to the product's reorder_point\n",
        "\n",
        "**Active products only**: Exclude products where discontinued = true unless specifically analyzing discontinued items\n",
        "\n",
        "**Stock valuation**: quantity_on_hand * unit_cost for each product\n",
        "\n",
        "## Example Query\n",
        "\n",
        "-- Find products below reorder point across all warehouses\n",
        "SELECT\n",
        "    p.product_id,\n",
        "    p.product_name,\n",
        "    p.reorder_point,\n",
        "    SUM(i.quantity_on_hand) as total_stock,\n",
        "    p.unit_cost,\n",
        "    (p.reorder_point - SUM(i.quantity_on_hand)) as units_to_reorder\n",
        "FROM products p\n",
        "JOIN inventory i ON p.product_id = i.product_id\n",
        "WHERE p.discontinued = false\n",
        "GROUP BY p.product_id, p.product_name, p.reorder_point, p.unit_cost\n",
        "HAVING SUM(i.quantity_on_hand) <= p.reorder_point\n",
        "ORDER BY units_to_reorder DESC;\n",
        "\"\"\",\n",
        "    },\n",
        "]\n",
        "\n",
        "# Create skill loading tool\n",
        "@tool\n",
        "def load_skill(skill_name: str) -> str:\n",
        "    \"\"\"Load the full content of a skill into the agent's context.\n",
        "\n",
        "    Use this when you need detailed information about how to handle a specific\n",
        "    type of request. This will provide you with comprehensive instructions,\n",
        "    policies, and guidelines for the skill area.\n",
        "\n",
        "    Args:\n",
        "        skill_name: The name of the skill to load (e.g., \"sales_analytics\", \"inventory_management\")\n",
        "    \"\"\"\n",
        "    # Find and return the requested skill\n",
        "    for skill in SKILLS:\n",
        "        if skill[\"name\"] == skill_name:\n",
        "            return f\"Loaded skill: {skill_name}\\n\\n{skill['content']}\"\n",
        "\n",
        "    # Skill not found\n",
        "    available = \", \".join(s[\"name\"] for s in SKILLS)\n",
        "    return f\"Skill '{skill_name}' not found. Available skills: {available}\"\n",
        "\n",
        "# Create skill middleware\n",
        "class SkillMiddleware(AgentMiddleware):\n",
        "    \"\"\"Middleware that injects skill descriptions into the system prompt.\"\"\"\n",
        "\n",
        "    # Register the load_skill tool as a class variable\n",
        "    tools = [load_skill]\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize and generate the skills prompt from SKILLS.\"\"\"\n",
        "        # Build skills prompt from the SKILLS list\n",
        "        skills_list = []\n",
        "        for skill in SKILLS:\n",
        "            skills_list.append(\n",
        "                f\"- **{skill['name']}**: {skill['description']}\"\n",
        "            )\n",
        "        self.skills_prompt = \"\\n\".join(skills_list)\n",
        "\n",
        "    def wrap_model_call(\n",
        "        self,\n",
        "        request: ModelRequest,\n",
        "        handler: Callable[[ModelRequest], ModelResponse],\n",
        "    ) -> ModelResponse:\n",
        "        \"\"\"Sync: Inject skill descriptions into system prompt.\"\"\"\n",
        "        # Build the skills addendum\n",
        "        skills_addendum = (\n",
        "            f\"\\n\\n## Available Skills\\n\\n{self.skills_prompt}\\n\\n\"\n",
        "            \"Use the load_skill tool when you need detailed information \"\n",
        "            \"about handling a specific type of request.\"\n",
        "        )\n",
        "\n",
        "        # Append to system message content blocks\n",
        "        new_content = list(request.system_message.content_blocks) + [\n",
        "            {\"type\": \"text\", \"text\": skills_addendum}\n",
        "        ]\n",
        "        new_system_message = SystemMessage(content=new_content)\n",
        "        modified_request = request.override(system_message=new_system_message)\n",
        "        return handler(modified_request)\n",
        "\n",
        "# Initialize your chat model (replace with your model)\n",
        "# Example: from langchain_anthropic import ChatAnthropic\n",
        "# model = ChatAnthropic(model=\"claude-3-5-sonnet-20241022\")\n",
        "from langchain_openai import ChatOpenAI\n",
        "model = ChatOpenAI(model=\"gpt-4\")\n",
        "\n",
        "# Create the agent with skill support\n",
        "agent = create_agent(\n",
        "    model,\n",
        "    system_prompt=(\n",
        "        \"You are a SQL query assistant that helps users \"\n",
        "        \"write queries against business databases.\"\n",
        "    ),\n",
        "    middleware=[SkillMiddleware()],\n",
        "    checkpointer=InMemorySaver(),\n",
        ")\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Configuration for this conversation thread\n",
        "    thread_id = str(uuid.uuid4())\n",
        "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
        "\n",
        "    # Ask for a SQL query\n",
        "    result = agent.invoke(\n",
        "        {\n",
        "            \"messages\": [\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": (\n",
        "                        \"Write a SQL query to find all customers \"\n",
        "                        \"who made orders over $1000 in the last month\"\n",
        "                    ),\n",
        "                }\n",
        "            ]\n",
        "        },\n",
        "        config\n",
        "    )\n",
        "\n",
        "    # Print the conversation\n",
        "    for message in result[\"messages\"]:\n",
        "        if hasattr(message, 'pretty_print'):\n",
        "            message.pretty_print()\n",
        "        else:\n",
        "            print(f\"{message.type}: {message.content}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "411Kn26NQpL2",
        "outputId": "dec03389-634e-44ce-e748-058e134ed42d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Write a SQL query to find all customers who made orders over $1000 in the last month\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  load_skill (call_ySVaHRbqVXDPeH3Adsq7QaDX)\n",
            " Call ID: call_ySVaHRbqVXDPeH3Adsq7QaDX\n",
            "  Args:\n",
            "    skill_name: sales_analytics\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: load_skill\n",
            "\n",
            "Loaded skill: sales_analytics\n",
            "\n",
            "# Sales Analytics Schema\n",
            "\n",
            "## Tables\n",
            "\n",
            "### customers\n",
            "- customer_id (PRIMARY KEY)\n",
            "- name\n",
            "- email\n",
            "- signup_date\n",
            "- status (active/inactive)\n",
            "- customer_tier (bronze/silver/gold/platinum)\n",
            "\n",
            "### orders\n",
            "- order_id (PRIMARY KEY)\n",
            "- customer_id (FOREIGN KEY -> customers)\n",
            "- order_date\n",
            "- status (pending/completed/cancelled/refunded)\n",
            "- total_amount\n",
            "- sales_region (north/south/east/west)\n",
            "\n",
            "### order_items\n",
            "- item_id (PRIMARY KEY)\n",
            "- order_id (FOREIGN KEY -> orders)\n",
            "- product_id\n",
            "- quantity\n",
            "- unit_price\n",
            "- discount_percent\n",
            "\n",
            "## Business Logic\n",
            "\n",
            "**Active customers**: status = 'active' AND signup_date <= CURRENT_DATE - INTERVAL '90 days'\n",
            "\n",
            "**Revenue calculation**: Only count orders with status = 'completed'. Use total_amount from orders table, which already accounts for discounts.\n",
            "\n",
            "**Customer lifetime value (CLV)**: Sum of all completed order amounts for a customer.\n",
            "\n",
            "**High-value orders**: Orders with total_amount > 1000\n",
            "\n",
            "## Example Query\n",
            "\n",
            "-- Get top 10 customers by revenue in the last quarter\n",
            "SELECT\n",
            "    c.customer_id,\n",
            "    c.name,\n",
            "    c.customer_tier,\n",
            "    SUM(o.total_amount) as total_revenue\n",
            "FROM customers c\n",
            "JOIN orders o ON c.customer_id = o.customer_id\n",
            "WHERE o.status = 'completed'\n",
            "  AND o.order_date >= CURRENT_DATE - INTERVAL '3 months'\n",
            "GROUP BY c.customer_id, c.name, c.customer_tier\n",
            "ORDER BY total_revenue DESC\n",
            "LIMIT 10;\n",
            "\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Based on the sales analytics skill, here is the SQL query to find all customers who made orders over $1000 in the last month:\n",
            "\n",
            "```sql\n",
            "SELECT\n",
            "    c.customer_id,\n",
            "    c.name,\n",
            "    SUM(o.total_amount) AS total_amount\n",
            "FROM customers c\n",
            "JOIN orders o ON c.customer_id = o.customer_id\n",
            "WHERE o.status = 'completed'\n",
            "    AND o.order_date >= CURRENT_DATE - INTERVAL '1 month'\n",
            "GROUP BY c.customer_id, c.name\n",
            "HAVING SUM(o.total_amount) > 1000;\n",
            "```\n",
            "\n",
            "In this query, you will find the `customer_id` and `name` for customers who have a total order amount greater than $1000 in the past month. The `JOIN` operation combines rows from `customers` and `orders` based on `customer_id`. The `WHERE` clause filters for completed orders made within the last month. The `GROUP BY` clause groups the selected rows by `customer_id` and `name`. The `HAVING` clause filters the results to include only those with a total order amount greater than $1000.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Medical Context - Agentic Skills Example"
      ],
      "metadata": {
        "id": "cpUDHqPPE4U8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CFO9gY78E9No"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "from typing import TypedDict\n",
        "from langchain.tools import tool\n",
        "from langchain.agents import create_agent\n",
        "from langchain.agents.middleware import ModelRequest, ModelResponse, AgentMiddleware\n",
        "from langchain.messages import SystemMessage\n",
        "from langgraph.checkpoint.memory import InMemorySaver\n",
        "from typing import Callable\n"
      ],
      "metadata": {
        "id": "vbR8k_njRcGq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# Skill definition\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "class Skill(TypedDict):\n",
        "    name: str\n",
        "    description: str\n",
        "    content: str\n",
        "\n",
        "\n",
        "SKILLS: list[Skill] = [\n",
        "    {\n",
        "        \"name\": \"search_decision_skill\",\n",
        "        \"description\": \"Decide whether a user query requires literature search.\",\n",
        "        \"content\": \"\"\"# Search Decision Skill\n",
        "\n",
        "Return ONE decision:\n",
        "\n",
        "##DECISION##:\n",
        "- SEARCH_REQUIRED\n",
        "\n",
        "OR\n",
        "\n",
        "##DECISION##:\n",
        "- ANSWER_FROM_CONTEXT\n",
        "\n",
        "OR\n",
        "\n",
        "##DECISION##:\n",
        "- ASK_CLARIFICATION: <short question>\n",
        "\n",
        "\n",
        "NOTE: - Stop immediately after the decision and don't output any more text\n",
        "\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"clinical_answer_evaluator\",\n",
        "        \"description\": \"Evaluate answer quality and safety.\",\n",
        "        \"content\": \"... (your existing one) ...\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"citation_verifier_skill\",\n",
        "        \"description\": \"Verify citations support claims.\",\n",
        "        \"content\": \"\"\"# Citation Verification Skill\n",
        "Return:\n",
        "\n",
        "##DECISION##:\n",
        "- CITATIONS_VALID\n",
        "\n",
        "OR\n",
        "\n",
        "##DECISION##:\n",
        "- CITATION_MISMATCH: <reason>\n",
        "\"\"\"\n",
        "    },\n",
        "]\n"
      ],
      "metadata": {
        "id": "AktK-RNgFCrD"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def load_skill(skill_name: str) -> str:\n",
        "    \"\"\"Load the full content of a skill into the agent's context.\"\"\"\n",
        "    for skill in SKILLS:\n",
        "        if skill[\"name\"] == skill_name:\n",
        "            return f\"Loaded skill: {skill_name}\\n\\n{skill['content']}\"\n",
        "    return f\"Skill '{skill_name}' not found.\"\n",
        "\n",
        "\n",
        "\n",
        "class SkillMiddleware(AgentMiddleware):\n",
        "    tools = [load_skill]\n",
        "\n",
        "    def __init__(self):\n",
        "        skills_list = [\n",
        "            f\"- **{skill['name']}**: {skill['description']}\"\n",
        "            for skill in SKILLS\n",
        "        ]\n",
        "        self.skills_prompt = \"\\n\".join(skills_list)\n",
        "\n",
        "    def wrap_model_call(\n",
        "        self,\n",
        "        request: ModelRequest,\n",
        "        handler: Callable[[ModelRequest], ModelResponse],\n",
        "    ) -> ModelResponse:\n",
        "        skills_addendum = (\n",
        "            f\"\\n\\n## Available Skills\\n\\n{self.skills_prompt}\\n\\n\"\n",
        "            \"Use the load_skill tool when you need to evaluate a clinical response.\"\n",
        "        )\n",
        "\n",
        "        new_content = list(request.system_message.content_blocks) + [\n",
        "            {\"type\": \"text\", \"text\": skills_addendum}\n",
        "        ]\n",
        "        new_system_message = SystemMessage(content=new_content)\n",
        "        return handler(request.override(system_message=new_system_message))"
      ],
      "metadata": {
        "id": "9wfjpT-9FE9t"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "model = ChatOpenAI(model=\"gpt-4.1\")\n",
        "\n",
        "agent = create_agent(\n",
        "    model,\n",
        "    system_prompt=(\n",
        "        \"You are a medical assistant chatbot that supports special skills.\\n\"\n",
        "        \"When a user query requires a specialized capability (like deciding whether \"\n",
        "        \"to search literature, evaluating an answer, or verifying citations), \"\n",
        "        \"you should explicitly load the appropriate skill using the load_skill tool.\\n\\n\"\n",
        "        \"Process for every user query:\\n\"\n",
        "        \"1. Analyze the user question.\\n\"\n",
        "        \"2. Decide if a skill should be loaded (e.g., search_decision_skill, \"\n",
        "        \"clinical_answer_evaluator, citation_verifier_skill).\\n\"\n",
        "        \"3. If a skill is needed, call the load_skill tool with the skill name.\\n\"\n",
        "        \"4. Use the loaded skill content and follow its instructions.\\n\\n\"\n",
        "        \"Do not answer anything outside of the guildelines from the skill\"\n",
        "    ),\n",
        "    middleware=[SkillMiddleware()],\n",
        "    checkpointer=InMemorySaver(),\n",
        ")\n"
      ],
      "metadata": {
        "id": "RUMxj_jVNles"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    thread_id = str(uuid.uuid4())\n",
        "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
        "\n",
        "    result = agent.invoke(\n",
        "        {\n",
        "            \"messages\": [\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": (\n",
        "                        \"User question:\\n\"\n",
        "                        \"how to treat lower back pain?\\n\\n\"\n",
        "                    ),\n",
        "                }\n",
        "            ]\n",
        "        },\n",
        "        config\n",
        "    )\n",
        "\n",
        "    for message in result[\"messages\"]:\n",
        "        print(message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvCA4sQtNpui",
        "outputId": "b84c033a-e9a1-45e3-db6f-23c37b2df6b1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User question:\n",
            "how to treat lower back pain?\n",
            "\n",
            "\n",
            "\n",
            "Loaded skill: search_decision_skill\n",
            "\n",
            "# Search Decision Skill\n",
            "\n",
            "Return ONE decision:\n",
            "\n",
            "##DECISION##:\n",
            "- SEARCH_REQUIRED\n",
            "\n",
            "OR\n",
            "\n",
            "##DECISION##:\n",
            "- ANSWER_FROM_CONTEXT\n",
            "\n",
            "OR\n",
            "\n",
            "##DECISION##:\n",
            "- ASK_CLARIFICATION: <short question>\n",
            "\n",
            "\n",
            "NOTE: - Stop immediately after the decision and don't output any more text\n",
            "\n",
            "##DECISION##:\n",
            "- ANSWER_FROM_CONTEXT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One conversation thread\n",
        "thread_id = str(uuid.uuid4())\n",
        "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
        "\n",
        "print(\"\\nðŸ§  Meddit Skill Demo Chatbot\")\n",
        "print(\"Type 'exit' to quit.\\n\")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"ðŸ‘¤ User: \").strip()\n",
        "    if user_input.lower() in {\"exit\", \"quit\"}:\n",
        "        print(\"\\nðŸ‘‹ Goodbye!\")\n",
        "        break\n",
        "\n",
        "    result = agent.invoke(\n",
        "        {\n",
        "            \"messages\": [\n",
        "                {\"role\": \"user\", \"content\": user_input}\n",
        "            ]\n",
        "        },\n",
        "        config\n",
        "    )\n",
        "\n",
        "    # Print assistant reply\n",
        "    for msg in reversed(result[\"messages\"]):\n",
        "        if msg.type == \"ai\":\n",
        "            print(f\"\\nðŸ¤– Assistant: {msg.content}\\n\")\n",
        "            break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 778
        },
        "id": "uqcrm-7jFe-c",
        "outputId": "27ae6168-a219-41a1-c853-616925e6b978"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ§  Meddit Skill Demo Chatbot\n",
            "Type 'exit' to quit.\n",
            "\n",
            "ðŸ‘¤ User: how to treat tmj\n",
            "\n",
            "ðŸ¤– Assistant: ##DECISION##:\n",
            "- SEARCH_REQUIRED\n",
            "\n",
            "ðŸ‘¤ User: what are the new research regarding covid 19 vaccines\n",
            "\n",
            "ðŸ¤– Assistant: ##DECISION##:\n",
            "- SEARCH_REQUIRED\n",
            "\n",
            "ðŸ‘¤ User: how are you today\n",
            "\n",
            "ðŸ¤– Assistant: I'm here to assist you with medical questions or concerns. How can I help you today?\n",
            "\n",
            "ðŸ‘¤ User: how do you evaluate the following: Upper gastrointestinal (GI) bleeding in adults is most commonly caused by peptic ulcer disease, gastritis, esophagitis, variceal bleeding, Mallory-Weiss syndrome, and malignancy, and requires prompt evaluation and management to reduce morbidity and mortality.\n",
            "\n",
            "ðŸ¤– Assistant: Loaded the clinical_answer_evaluator skill. Please provide the answer you want evaluated, or let me know if you want an assessment of the medical statement provided.\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1251327515.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ðŸ‘¤ User: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"exit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"quit\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nðŸ‘‹ Goodbye!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G0VJOQqDMVm7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}